import streamlit as st
import pandas as pd
import re
import requests
import json
import time
import datetime
import os
from io import StringIO

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®ç»Ÿè®¡åˆ†æå·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ====== é£ä¹¦å¤šç»´è¡¨æ ¼APIç›¸å…³é…ç½® ======
TOKEN_FILE = "feishu_token.json"
app_token = "MEwYb1UL4aSSpIsn6V5c9gzXnKe"
app_id = "cli_a8fdaf1afff39013"
app_secret = "o6qUUHKhMhymwaVM4u40H2zQAFrhdHm7"

def extract_total_views(views_str):
    """æå–æ’­æ”¾é‡ï¼Œå¤„ç†ä¸¤ç§ä¸åŒæ ¼å¼"""
    if not views_str or pd.isna(views_str):
        return 0
        
    views_str = str(views_str)
    
    # å¤„ç†æ ¼å¼2: æ€»æ’­æ”¾ï¼š1715(+9) è¿™ç§æ ¼å¼
    total_match = re.search(r'æ€»æ’­æ”¾[ï¼š:]\s*(\d+)(?:\(\+\d+\))?', views_str)
    if total_match:
        return int(total_match.group(1))
    
    # å¦‚æœæ²¡æœ‰æ€»æ’­æ”¾æ•°ï¼Œå°è¯•åŠ æ€»æ‰€æœ‰æ•°å­—
    numbers = re.findall(r'\d+', views_str)
    if numbers:
        return sum(int(num) for num in numbers)
    
    return 0

class FeishuLabTableReader:
    """é£ä¹¦Labè¡¨æ ¼è¯»å–å™¨"""
    
    def __init__(self, app_id: str, app_secret: str):
        """
        åˆå§‹åŒ–Labè¡¨æ ¼è¯»å–å™¨
        
        Args:
            app_id: é£ä¹¦åº”ç”¨çš„App ID
            app_secret: é£ä¹¦åº”ç”¨çš„App Secret
        """
        self.app_id = app_id
        self.app_secret = app_secret
        self.tenant_access_token = None
        self.app_token = "CSs1bClvYaIGl5snunycUcFpngf"  # labè¡¨æ ¼çš„app_token
        self.table_id = "tblJc7IxgQhQMkKN"  # labç›’å­æ¯æ—¥æ”¶å…¥è¡¨æ ¼ID
        self.base_url = "https://open.feishu.cn/open-apis/bitable/v1"
        
    def get_tenant_access_token(self) -> str:
        """è·å–tenant_access_token"""
        url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
        
        payload = {
            "app_id": self.app_id,
            "app_secret": self.app_secret
        }
        
        try:
            response = requests.post(url, json=payload)
            response.raise_for_status()
            
            result = response.json()
            
            if result.get("code") == 0:
                self.tenant_access_token = result.get("tenant_access_token")
                return self.tenant_access_token
            else:
                raise Exception(f"è·å–è®¿é—®å‡­è¯å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                
        except requests.RequestException as e:
            raise Exception(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
    
    def get_headers(self) -> dict:
        """è·å–è¯·æ±‚å¤´"""
        if not self.tenant_access_token:
            self.get_tenant_access_token()
            
        return {
            "Authorization": f"Bearer {self.tenant_access_token}",
            "Content-Type": "application/json"
        }
    
    def get_table_fields(self) -> list:
        """è·å–labè¡¨æ ¼çš„å­—æ®µä¿¡æ¯"""
        url = f"{self.base_url}/apps/{self.app_token}/tables/{self.table_id}/fields"
        
        try:
            response = requests.get(url, headers=self.get_headers())
            response.raise_for_status()
            
            result = response.json()
            if result.get("code") == 0:
                fields = result.get("data", {}).get("items", [])
                return fields
            else:
                raise Exception(f"è·å–å­—æ®µä¿¡æ¯å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                
        except requests.RequestException as e:
            raise Exception(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
    
    def get_table_records(self, page_size: int = 20) -> list:
        """è·å–labè¡¨æ ¼çš„è®°å½•"""
        url = f"{self.base_url}/apps/{self.app_token}/tables/{self.table_id}/records"
        
        params = {
            "page_size": page_size
        }
        
        try:
            response = requests.get(url, headers=self.get_headers(), params=params)
            response.raise_for_status()
            
            result = response.json()
            if result.get("code") == 0:
                records = result.get("data", {}).get("items", [])
                return records
            else:
                raise Exception(f"è·å–è®°å½•å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                
        except requests.RequestException as e:
            raise Exception(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
    

    def get_all_records(self) -> list:
        """è·å–æ‰€æœ‰è®°å½•ï¼ˆåˆ†é¡µè·å–ï¼‰"""
        all_records = []
        page_token = None
        
        while True:
            url = f"{self.base_url}/apps/{self.app_token}/tables/{self.table_id}/records"
            params = {"page_size": 500}
            if page_token:
                params["page_token"] = page_token
            
            try:
                response = requests.get(url, headers=self.get_headers(), params=params)
                response.raise_for_status()
                
                result = response.json()
                if result.get("code") == 0:
                    data = result.get("data", {})
                    records = data.get("items", [])
                    all_records.extend(records)
                    
                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šæ•°æ®
                    page_token = data.get("page_token")
                    if not page_token:
                        break
                else:
                    raise Exception(f"è·å–è®°å½•å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                    
            except requests.RequestException as e:
                raise Exception(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
        
        st.write(f"ğŸ“„ æ€»å…±è·å–åˆ° {len(all_records)} æ¡è®°å½•")
        return all_records

    def get_order_amount_by_owner_and_date(self, owner: str, target_date: datetime.date) -> float:
        """æ ¹æ®å½’å±å’Œæ—¥æœŸç­›é€‰æ•°æ®ï¼Œè®¡ç®—è®¢å•é‡‘é¢æ€»å’Œ"""
        try:
            st.write(f"ğŸ” æœç´¢æ¡ä»¶: åˆ†ç»„='{owner}', æ—¥æœŸ='{target_date}'")
            
            # è·å–å­—æ®µä¿¡æ¯
            fields = self.get_table_fields()
            field_map = {field['field_id']: field['field_name'] for field in fields}
            
            # æ‰¾åˆ°å…³é”®å­—æ®µçš„ID
            date_field_id = "è®¢å•æ—¥æœŸ"
            group_field_id = "åˆ†ç»„" 
            amount_field_id = "è®¢å•é‡‘é¢(å…ƒ)"
            
            st.write(f"ğŸ“‹ ä½¿ç”¨å…³é”®å­—æ®µ: åˆ†ç»„={group_field_id}, æ—¥æœŸ={date_field_id}, é‡‘é¢={amount_field_id}")
            
            # è½¬æ¢ç›®æ ‡æ—¥æœŸä¸ºæ—¶é—´æˆ³
            target_timestamp = None
            try:
                target_dt = datetime.datetime.combine(target_date, datetime.time.min)
                target_timestamp = int(target_dt.timestamp() * 1000)  # è½¬ä¸ºæ¯«ç§’æ—¶é—´æˆ³
                st.write(f"ğŸ• ç›®æ ‡æ—¥æœŸæ—¶é—´æˆ³: {target_timestamp}")
            except Exception as e:
                st.warning(f"âš ï¸ æ—¥æœŸè§£æå¤±è´¥: {e}")
                target_timestamp = None
            
            # è·å–æ‰€æœ‰è®°å½•
            all_records = self.get_all_records()
            
            # ç­›é€‰æ•°æ®
            matched_records = []
            total_amount = 0
            
            for record in all_records:
                record_fields = record.get('fields', {})
                
                # æ£€æŸ¥åˆ†ç»„
                group_value = record_fields.get(group_field_id)
                if not group_value or owner not in str(group_value):
                    continue
                
                # æ£€æŸ¥æ—¥æœŸï¼ˆå¦‚æœæŒ‡å®šäº†ï¼‰
                if target_timestamp and date_field_id:
                    date_value = record_fields.get(date_field_id)
                    if date_value:
                        try:
                            # å°†æ•°æ®åº“ä¸­çš„æ—¶é—´æˆ³è½¬æ¢ä¸ºæ—¥æœŸè¿›è¡Œæ¯”è¾ƒ
                            record_timestamp = int(date_value)
                            # æ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€å¤©ï¼ˆå…è®¸ä¸€å¤©çš„è¯¯å·®èŒƒå›´ï¼‰
                            day_in_ms = 24 * 60 * 60 * 1000
                            if abs(record_timestamp - target_timestamp) >= day_in_ms:
                                continue
                        except (ValueError, TypeError):
                            # å¦‚æœä¸æ˜¯æ—¶é—´æˆ³æ ¼å¼ï¼Œå°è¯•å­—ç¬¦ä¸²åŒ¹é…
                            date_str = str(date_value)
                            target_date_str = target_date.strftime("%Y-%m-%d")
                            if target_date_str not in date_str and target_date_str.replace('-', '/') not in date_str:
                                continue
                
                # è·å–é‡‘é¢
                amount_value = record_fields.get(amount_field_id)
                if amount_value:
                    try:
                        # å¤„ç†ä¸åŒçš„æ•°å­—æ ¼å¼
                        if isinstance(amount_value, (int, float)):
                            amount = float(amount_value)
                        else:
                            # ç§»é™¤å¯èƒ½çš„è´§å¸ç¬¦å·å’Œé€—å·
                            amount_str = str(amount_value).replace('ï¿¥', '').replace(',', '').strip()
                            amount = float(amount_str)
                        
                        total_amount += amount
                        
                        # æ ¼å¼åŒ–æ—¥æœŸæ˜¾ç¤º
                        date_display = record_fields.get(date_field_id, 'æœªçŸ¥')
                        if isinstance(date_display, int):
                            try:
                                # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºå¯è¯»æ—¥æœŸ
                                date_obj = datetime.datetime.fromtimestamp(date_display / 1000)
                                date_display = date_obj.strftime('%Y-%m-%d')
                            except:
                                date_display = str(date_display)
                        
                        matched_records.append({
                            'group': group_value,
                            'date': date_display,
                            'amount': amount,
                            'record': record_fields
                        })
                    except (ValueError, TypeError):
                        st.warning(f"âš ï¸ æ— æ³•è§£æé‡‘é¢: {amount_value}")
                        continue
            
            # æ˜¾ç¤ºç»“æœ
            st.write(f"ğŸ¯ æœç´¢ç»“æœ: æ‰¾åˆ°åŒ¹é…è®°å½• {len(matched_records)} æ¡, æ€»é‡‘é¢: Â¥{total_amount:,.2f}")
            
            if matched_records:
                st.write("ğŸ“‹ åŒ¹é…çš„è®°å½•:")
                # åˆ›å»ºDataFrameæ˜¾ç¤ºç»“æœ
                display_data = []
                for item in matched_records:
                    display_data.append({
                        'åˆ†ç»„': item['group'],
                        'æ—¥æœŸ': item['date'],
                        'é‡‘é¢': f"Â¥{item['amount']:.2f}"
                    })
                
                df_result = pd.DataFrame(display_data)
                st.dataframe(df_result, height=200)
            
            return total_amount
            
        except Exception as e:
            st.error(f"è®¡ç®—è®¢å•é‡‘é¢å¤±è´¥: {str(e)}")
            return 0.0

class TokenManager:
    def __init__(self):
        self.token_file = TOKEN_FILE
        self.token_data = self._load_token_data()

    def _load_token_data(self):
        if os.path.exists(self.token_file):
            try:
                with open(self.token_file, 'r') as f:
                    return json.load(f)
            except:
                return {}
        return {}

    def _save_token_data(self):
        with open(self.token_file, 'w') as f:
            json.dump(self.token_data, f)

    def get_tenant_access_token(self):
        """è·å–æˆ–åˆ·æ–°tenant_access_token"""
        current_time = int(time.time())
        
        # æ£€æŸ¥ç°æœ‰tokenæ˜¯å¦è¿˜æœ‰æ•ˆ
        if (self.token_data.get('tenant_access_token') and 
            self.token_data.get('expire_time', 0) > current_time + 60):
            return self.token_data['tenant_access_token']

        # è·å–æ–°token
        url = "https://open.feishu.cn/open-apis/auth/v3/app_access_token/internal"
        data = {
            "app_id": app_id,
            "app_secret": app_secret
        }
        try:
            response = requests.post(url, json=data)
            resp_data = response.json()
            
            if resp_data.get("code") == 0:
                token = resp_data.get("tenant_access_token")
                expire = resp_data.get("expire")
                
                self.token_data = {
                    'tenant_access_token': token,
                    'expire_time': current_time + expire
                }
                self._save_token_data()
                return token
                
            raise Exception(f"è·å–tenant_access_tokenå¤±è´¥: {resp_data}")
        except Exception as e:
            st.error(f"è·å–tokenå¼‚å¸¸: {e}")
            raise

def get_tables(token_manager, app_token):
    """è·å–è¡¨æ ¼IDï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    max_retries = 3
    for attempt in range(max_retries):
        try:
            url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{app_token}/tables"
            token = token_manager.get_tenant_access_token()
            headers = {'Authorization': f'Bearer {token}'}
            resp = requests.get(url, headers=headers)
            data = resp.json()
            
            if data.get("code") == 0:
                return data["data"]["items"][0]["table_id"]
            elif data.get("code") in [99991677, 99991661]:
                token_manager.token_data = {}
                continue
            else:
                raise Exception(f"è·å–table_idå¤±è´¥: {data}")
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            time.sleep(1)

def add_record(token_manager, app_token, table_id, fields):
    """æ·»åŠ è®°å½•ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    max_retries = 3
    for attempt in range(max_retries):
        try:
            url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{app_token}/tables/{table_id}/records"
            token = token_manager.get_tenant_access_token()
            headers = {
                'Authorization': f'Bearer {token}',
                'Content-Type': 'application/json'
            }
            data = {"fields": fields}
            
            resp = requests.post(url, headers=headers, json=data)
            result = resp.json()
            
            if result.get("code") == 0:
                return result
            elif result.get("code") in [99991677, 99991661]:
                token_manager.token_data = {}
                continue
            else:
                raise Exception(f"å†™å…¥è®°å½•å¤±è´¥: {result}")
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            time.sleep(1)

def date_to_timestamp(date_str):
    """å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºæ—¶é—´æˆ³"""
    try:
        if '-' in date_str:
            dt = datetime.datetime.strptime(date_str, "%Y-%m-%d")
        elif '.' in date_str:
            month_day = date_str.split('.')
            if len(month_day) >= 2:
                month = month_day[0].zfill(2)
                day = month_day[1].zfill(2)
                dt = datetime.datetime.strptime(f"2025-{month}-{day}", "%Y-%m-%d")
        dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)
        return int(dt.timestamp() * 1000)
    except Exception as e:
        st.error(f"æ—¥æœŸè½¬æ¢å¤±è´¥: {e}")
        return None

def read_data_file(file_content, file_name):
    """è¯»å–ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹"""
    try:
        if file_name.endswith('.csv'):
            return pd.read_csv(StringIO(file_content.decode('utf-8')))
        elif file_name.endswith('.xlsx'):
            from io import BytesIO
            return pd.read_excel(BytesIO(file_content))
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_name}")
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return None

def process_data_file(df, default_upload_count):
    """å¤„ç†æ•°æ®æ–‡ä»¶ï¼Œè¿”å›ç»Ÿè®¡ç»“æœ"""
    results = {
        'total_uploads': 0,
        'total_views': 0
    }
    
    # è®¡ç®—ä¸Šä¼ æˆåŠŸæ€»æ•°
    if "ä¸Šä¼ æ•°é‡" in df.columns:
        upload_column = df["ä¸Šä¼ æ•°é‡"].fillna(0).astype(int)
        success_counts = default_upload_count - upload_column
        success_counts = success_counts.apply(lambda x: max(x, 0))
        results['total_uploads'] = success_counts.sum()
    
    # æå–æ’­æ”¾é‡
    play_column = None
    for col in df.columns:
        if 'æ’­æ”¾' in str(col):
            play_column = col
            header_match = re.search(r'æ’­æ”¾\((\d+)\)', str(col))
            if header_match:
                results['total_views'] = int(header_match.group(1))
                break
    
    if results['total_views'] == 0 and play_column:
        for views_str in df[play_column]:
            results['total_views'] += extract_total_views(views_str)
    
    return results

# Streamlit ç•Œé¢
def main():
    st.title("ğŸ“Š æ•°æ®ç»Ÿè®¡åˆ†æå·¥å…·")
    st.markdown("---")
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®å‚æ•°")
        
        # å½’å±è¾“å…¥
        owner = st.text_input("å½’å±", placeholder="ä¾‹å¦‚ï¼šä¸­ç§‘ã€åŒ—æ–—")
        
        # æ—¥æœŸè¾“å…¥
        date_input = st.date_input("æ—¥æœŸ", datetime.date.today())
        
        # é»˜è®¤ä¸Šä¼ è§†é¢‘æ•°é‡
        default_upload_count = st.number_input("é»˜è®¤ä¸Šä¼ è§†é¢‘æ•°é‡", min_value=1, value=3)
        
        st.markdown("---")
        st.markdown("### ğŸ“‹ ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. å¡«å†™å½’å±ä¿¡æ¯
        2. é€‰æ‹©æ—¥æœŸ
        3. è®¾ç½®é»˜è®¤ä¸Šä¼ è§†é¢‘æ•°é‡
        4. ä¸Šä¼ CSVæˆ–Excelæ–‡ä»¶
        5. ç‚¹å‡»åˆ†ææŒ‰é’®
        
        ğŸ’¡ **æ³¨æ„**: Labè®¢å•é‡‘é¢ä¼šè‡ªåŠ¨æŸ¥è¯¢å‰ä¸€å¤©çš„æ•°æ®
        """)
    
    # ä¸»ç•Œé¢
    st.header("ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
    uploaded_files = st.file_uploader(
        "é€‰æ‹©æ•°æ®æ–‡ä»¶",
        type=['csv', 'xlsx'],
        accept_multiple_files=True,
        help="æ”¯æŒCSVå’ŒExcelæ ¼å¼ï¼Œå¯ä»¥åŒæ—¶ä¸Šä¼ å¤šä¸ªæ–‡ä»¶"
    )
    
    if uploaded_files:
        st.success(f"âœ… å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
        with st.expander("ğŸ“‹ æŸ¥çœ‹ä¸Šä¼ çš„æ–‡ä»¶", expanded=True):
            for i, file in enumerate(uploaded_files, 1):
                file_size = len(file.getvalue()) / 1024  # KB
                st.write(f"{i}. ğŸ“„ **{file.name}** ({file_size:.1f} KB)")
    
    # æ“ä½œæŒ‰é’®
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        analyze_button = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True, disabled=not (uploaded_files and owner))
    
    with col2:
        if st.button("ğŸ”„ æ¸…é™¤ç»“æœ", use_container_width=True):
            st.rerun()
    
    with col3:
        # æ·»åŠ ç¤ºä¾‹æ•°æ®ä¸‹è½½
        if st.button("ğŸ“¥ ä¸‹è½½ç¤ºä¾‹", use_container_width=True):
            st.info("ğŸ’¡ ç¤ºä¾‹æ•°æ®æ ¼å¼è¯´æ˜å·²æ˜¾ç¤ºåœ¨ä¸‹æ–¹")
    
    # åˆå§‹åŒ– session state
    if 'analysis_results' not in st.session_state:
        st.session_state.analysis_results = None
    if 'analysis_params' not in st.session_state:
        st.session_state.analysis_params = None
    
    # åˆ†æå¤„ç†
    if analyze_button and uploaded_files and owner:
        with st.spinner("æ­£åœ¨åˆ†ææ•°æ®..."):
            try:
                # åˆå§‹åŒ–ç»Ÿè®¡ç»“æœ
                all_results = {
                    'total_uploads': 0,
                    'total_views': 0
                }
                
                # å¤„ç†æ¯ä¸ªæ–‡ä»¶
                progress_bar = st.progress(0)
                for i, uploaded_file in enumerate(uploaded_files):
                    file_content = uploaded_file.read()
                    df = read_data_file(file_content, uploaded_file.name)
                    
                    if df is not None:
                        file_results = process_data_file(df, default_upload_count)
                        
                        # ç´¯åŠ ç»“æœ
                        for key in all_results:
                            all_results[key] += file_results[key]
                        
                        st.write(f"âœ… {uploaded_file.name}: æ’­æ”¾é‡ {file_results['total_views']}, ä¸Šä¼ æˆåŠŸ {file_results['total_uploads']}")
                    
                    progress_bar.progress((i + 1) / len(uploaded_files))
                
                # è‡ªåŠ¨è·å–Labè®¢å•é‡‘é¢ï¼ˆæŸ¥è¯¢å‰ä¸€å¤©çš„æ•°æ®ï¼‰
                st.write("ğŸ” æ­£åœ¨è·å–Labè®¢å•é‡‘é¢...")
                try:
                    # è®¡ç®—å‰ä¸€å¤©çš„æ—¥æœŸ
                    previous_date = date_input - datetime.timedelta(days=1)
                    st.write(f"ğŸ’¡ æŸ¥è¯¢å‰ä¸€å¤©çš„è®¢å•é‡‘é¢: {previous_date}")
                    
                    lab_reader = FeishuLabTableReader(app_id, app_secret)
                    order_amount = lab_reader.get_order_amount_by_owner_and_date(owner, previous_date)
                    
                    if order_amount > 0:
                        st.write(f"ğŸ’° è·å–åˆ°Labè®¢å•é‡‘é¢: Â¥{order_amount:.2f}")
                    else:
                        st.write("âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„Labè®¢å•æ•°æ®ï¼Œè®¢å•é‡‘é¢ä¸º Â¥0.00")
                        order_amount = 0.0
                        
                except Exception as e:
                    st.warning(f"âš ï¸ è·å–Labè®¢å•é‡‘é¢å¤±è´¥: {str(e)}ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ Â¥0.00")
                    order_amount = 0.0
                
                # ä¿å­˜ç»“æœåˆ° session state
                st.session_state.analysis_results = {
                    'all_results': all_results,
                    'order_amount': order_amount
                }
                st.session_state.analysis_params = {
                    'owner': owner,
                    'date_input': date_input,
                    'file_count': len(uploaded_files)
                }
                
            except Exception as e:
                st.error(f"âŒ åˆ†æå¤±è´¥: {e}")
    
    # æ˜¾ç¤ºåˆ†æç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if st.session_state.analysis_results is not None:
        results = st.session_state.analysis_results
        params = st.session_state.analysis_params
        
        all_results = results['all_results']
        
        # æ˜¾ç¤ºç»“æœ
        st.markdown("---")
        st.header("ğŸ“ˆ åˆ†æç»“æœ")
        
        # åˆ›å»ºæŒ‡æ ‡å¡ç‰‡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»ä¸Šä¼ æˆåŠŸ", all_results['total_uploads'])
        with col2:
            st.metric("æ€»æ’­æ”¾é‡", f"{all_results['total_views']:,}")
        with col3:
            order_amount = st.session_state.analysis_results.get('order_amount', 0)
            st.metric("Labè®¢å•é‡‘é¢", f"Â¥{order_amount:.2f}")
        with col4:
            st.metric("æ–‡ä»¶æ•°é‡", params['file_count'])
        
        # è¯¦ç»†ç»Ÿè®¡
        with st.expander("ğŸ“Š è¯¦ç»†ç»Ÿè®¡"):
            order_amount = st.session_state.analysis_results.get('order_amount', 0)
            previous_date = params['date_input'] - datetime.timedelta(days=1)
            st.write("**æ±‡æ€»æ•°æ®:**")
            st.write(f"- å½’å±: {params['owner']}")
            st.write(f"- æ—¥æœŸ: {params['date_input']}")
            st.write(f"- æ–‡ä»¶æ•°é‡: {params['file_count']}")
            st.write(f"- æ€»ä¸Šä¼ æˆåŠŸ: {all_results['total_uploads']}")
            st.write(f"- æ€»æ’­æ”¾é‡: {all_results['total_views']:,}")
            st.write(f"- Labè®¢å•é‡‘é¢: Â¥{order_amount:.2f} (æŸ¥è¯¢æ—¥æœŸ: {previous_date})")
        

        
        # å†™å…¥é£ä¹¦è¡¨æ ¼
        if st.button("ğŸ’¾ ä¿å­˜åˆ°é£ä¹¦è¡¨æ ¼", type="primary"):
            with st.spinner("æ­£åœ¨ä¿å­˜åˆ°é£ä¹¦è¡¨æ ¼..."):
                try:
                    token_manager = TokenManager()
                    table_id = get_tables(token_manager, app_token)
                    
                    # è½¬æ¢æ—¥æœŸä¸ºæ—¶é—´æˆ³
                    timestamp = date_to_timestamp(params['date_input'].strftime("%Y-%m-%d"))
                    
                    # è·å–è®¢å•é‡‘é¢
                    order_amount = st.session_state.analysis_results.get('order_amount', 0)
                    
                    fields = {
                        "å½’å±": params['owner'],
                        "æ—¥æœŸ": timestamp,
                        "å‘å¸ƒè§†é¢‘æ•°é‡": int(all_results['total_uploads']),
                        "æ€»æ’­æ”¾é‡": int(all_results['total_views']),
                        "å‡ºå•é‡‘é¢": float(order_amount)  # æ·»åŠ å‡ºå•é‡‘é¢å­—æ®µ
                    }
                    
                    result = add_record(token_manager, app_token, table_id, fields)
                    st.success("âœ… æ•°æ®å·²æˆåŠŸä¿å­˜åˆ°é£ä¹¦è¡¨æ ¼ï¼")
                    
                    # æ¸…é™¤ç»“æœï¼Œé¿å…é‡å¤ä¿å­˜
                    if st.button("ğŸ”„ æ¸…é™¤ç»“æœ"):
                        st.session_state.analysis_results = None
                        st.session_state.analysis_params = None
                        st.rerun()
                    
                except Exception as e:
                    st.error(f"âŒ ä¿å­˜å¤±è´¥: {e}")
                    st.write("é”™è¯¯è¯¦æƒ…:", str(e))
                
    elif analyze_button:
        if not uploaded_files:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ–‡ä»¶")
        if not owner:
            st.warning("âš ï¸ è¯·å¡«å†™å½’å±ä¿¡æ¯")
    
    # åº•éƒ¨è¯´æ˜
    st.markdown("---")
    with st.expander("ğŸ“– æ•°æ®æ ¼å¼è¯´æ˜"):
        st.markdown("""
        ### æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        - **CSVæ–‡ä»¶**: `.csv` æ ¼å¼
        - **Excelæ–‡ä»¶**: `.xlsx` æ ¼å¼
        
        ### å¿…éœ€çš„æ•°æ®åˆ—
        - **ä¸Šä¼ æ•°é‡**: ä¸Šä¼ å¤±è´¥çš„è§†é¢‘æ•°é‡
        - **æ’­æ”¾é‡ç›¸å…³åˆ—**: åˆ—ååŒ…å«"æ’­æ”¾"å­—æ ·çš„åˆ—
        
        ### ç¤ºä¾‹æ•°æ®ç»“æ„
        ```
        çŠ¶æ€ | ä¸Šä¼ æ•°é‡ | æ’­æ”¾(1234567) | å…¶ä»–åˆ—...
        ä¸Šä¼ æˆåŠŸ#3ä¸ª | 0 | æ€»æ’­æ”¾ï¼š1715(+9) | ...
        ```
        """)
    
    # ç‰ˆæƒä¿¡æ¯
    st.markdown("---")
    st.markdown(
        "<div style='text-align: center; color: #666; font-size: 0.8em;'>"
        "ğŸ“Š æ•°æ®ç»Ÿè®¡åˆ†æå·¥å…· | åŸºäº Streamlit æ„å»º"
        "</div>", 
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()